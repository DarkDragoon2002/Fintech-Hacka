{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation,concatenate, Attention, Bidirectional,GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.layers import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTMPrediction(training_df, time_step = 10, runs = 30, end_date=datetime.strftime(datetime.now(), '%Y-%m-%d')):\n",
    "\n",
    "    #Data Scaling\n",
    "    Xscaler = MinMaxScaler()\n",
    "    Xdata = Xscaler.fit_transform(np.array(training_df))\n",
    "    Xdata.shape\n",
    "    Yscaler = MinMaxScaler()\n",
    "    Ydata = Yscaler.fit_transform(np.array([training_df['Close']]).transpose())\n",
    "\n",
    "    Xtrain_data, Xtest_data = train_test_split(Xdata, test_size=0.3, shuffle=False)\n",
    "    Ytrain_data, Ytest_data = train_test_split(Ydata, test_size=0.3, shuffle=False)\n",
    "    \n",
    "    def build_timeseries(Xdata, Ydata, time_step):\n",
    "        dim_0 = Xdata.shape[0] - time_step\n",
    "        dim_1 = Xdata.shape[1]\n",
    "\n",
    "        x = np.zeros((dim_0, time_step, dim_1))\n",
    "        y = np.zeros((Ydata.shape[0] - time_step,))\n",
    "\n",
    "        for i in range(dim_0):\n",
    "            x[i] = Xdata[i:time_step+i]\n",
    "            y[i] = Ydata[time_step+i]\n",
    "        return x, y\n",
    "\n",
    "    \n",
    "    X_train, Y_train = build_timeseries(Xtrain_data, Ytrain_data.transpose()[0], time_step)\n",
    "    X_test, Y_test = build_timeseries(Xtest_data, Ytest_data.transpose()[0], time_step)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], time_step, X_train.shape[2]))\n",
    "    X_test = X_test.reshape((X_test.shape[0], time_step, X_test.shape[2]))\n",
    "\n",
    "    results = []\n",
    "    prediction_data = np.array([X_test[-1]])\n",
    "    for i in range(runs):\n",
    "        print(\"RUN: \", i+1)\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50,return_sequences = True,input_shape = (X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(LSTM(50,return_sequences = True))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss = 'mean_squared_error',optimizer = 'adam')\n",
    "        lstm_model = model.fit(X_train,Y_train,validation_data = (X_test,Y_test),epochs = 25,batch_size = 50, verbose = 1)\n",
    "        prediction = model.predict(prediction_data)\n",
    "        prediction = Yscaler.inverse_transform(prediction)[0][0]\n",
    "        print(\"Prediction for: \", end_date, \"        CLOSE: \", prediction)\n",
    "        results.append(prediction)\n",
    "\n",
    "    lastclose = Yscaler.inverse_transform([Ydata[-1]])[0][0]\n",
    "    adjresults = np.array([x - lastclose for x in results])\n",
    "    mu = adjresults.mean()\n",
    "    std = adjresults.std()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    xmin, xmax = plt.xlim()\n",
    "    diff = pd.DataFrame(adjresults) \n",
    "    kde = diff.plot.kde(ax=ax, legend = False)\n",
    "    diff.plot.hist(density=True, ax=ax, bins=20)\n",
    "    title = \"Fit Values: {:.2f} and {:.2f}\".format(mu, std) \n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    #Returns average change in price\n",
    "    return mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4812.087402</td>\n",
       "      <td>4619.649414</td>\n",
       "      <td>4822.363281</td>\n",
       "      <td>4619.649414</td>\n",
       "      <td>19290896267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4735.068848</td>\n",
       "      <td>4810.071289</td>\n",
       "      <td>4837.589355</td>\n",
       "      <td>4718.039062</td>\n",
       "      <td>20834172627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4636.174316</td>\n",
       "      <td>4733.362793</td>\n",
       "      <td>4859.502930</td>\n",
       "      <td>4485.093262</td>\n",
       "      <td>22748160545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4730.384277</td>\n",
       "      <td>4635.453613</td>\n",
       "      <td>4778.059082</td>\n",
       "      <td>4580.990234</td>\n",
       "      <td>17933201129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4667.115234</td>\n",
       "      <td>4724.306641</td>\n",
       "      <td>4808.738770</td>\n",
       "      <td>4510.920410</td>\n",
       "      <td>18316060208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>2219.337402</td>\n",
       "      <td>2316.110352</td>\n",
       "      <td>2316.892822</td>\n",
       "      <td>2214.263184</td>\n",
       "      <td>10259157898</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2226.926514</td>\n",
       "      <td>2220.415527</td>\n",
       "      <td>2260.809814</td>\n",
       "      <td>2213.550781</td>\n",
       "      <td>6866555430</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>2196.481201</td>\n",
       "      <td>2226.892578</td>\n",
       "      <td>2244.366455</td>\n",
       "      <td>2195.761719</td>\n",
       "      <td>7410453853</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>2217.273438</td>\n",
       "      <td>2195.341797</td>\n",
       "      <td>2222.019287</td>\n",
       "      <td>2120.127441</td>\n",
       "      <td>10366536490</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>2177.872559</td>\n",
       "      <td>2218.240967</td>\n",
       "      <td>2253.348877</td>\n",
       "      <td>2139.723389</td>\n",
       "      <td>10619179629</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Close         Open         High          Low       Volume  \\\n",
       "0    4812.087402  4619.649414  4822.363281  4619.649414  19290896267   \n",
       "1    4735.068848  4810.071289  4837.589355  4718.039062  20834172627   \n",
       "2    4636.174316  4733.362793  4859.502930  4485.093262  22748160545   \n",
       "3    4730.384277  4635.453613  4778.059082  4580.990234  17933201129   \n",
       "4    4667.115234  4724.306641  4808.738770  4510.920410  18316060208   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "767  2219.337402  2316.110352  2316.892822  2214.263184  10259157898   \n",
       "768  2226.926514  2220.415527  2260.809814  2213.550781   6866555430   \n",
       "769  2196.481201  2226.892578  2244.366455  2195.761719   7410453853   \n",
       "770  2217.273438  2195.341797  2222.019287  2120.127441  10366536490   \n",
       "771  2177.872559  2218.240967  2253.348877  2139.723389  10619179629   \n",
       "\n",
       "     Negative  Neutral  Positive  \n",
       "0         1.0      6.0       1.0  \n",
       "1         1.0      6.0       3.0  \n",
       "2         1.0      6.0       5.0  \n",
       "3         2.0      6.0       2.0  \n",
       "4         0.0      3.0       7.0  \n",
       "..        ...      ...       ...  \n",
       "767      20.0     24.0      20.0  \n",
       "768       6.0      6.0       4.0  \n",
       "769       2.0      8.0      12.0  \n",
       "770      11.0     17.0      33.0  \n",
       "771       3.0      4.0       3.0  \n",
       "\n",
       "[772 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadf = pd.read_csv('lstm_data.csv')\n",
    "dataseparate = datadf[['Close', 'Open', 'High', 'Low', 'Volume', 'Negative', 'Neutral', 'Positive']]\n",
    "display(dataseparate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN:  1\n",
      "WARNING:tensorflow:From c:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mLSTMPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataseparate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-12-20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 42\u001b[0m, in \u001b[0;36mLSTMPrediction\u001b[1;34m(training_df, time_step, runs, end_date)\u001b[0m\n\u001b[0;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(prediction_data)\n\u001b[0;32m     44\u001b[0m prediction \u001b[38;5;241m=\u001b[39m Yscaler\u001b[38;5;241m.\u001b[39minverse_transform(prediction)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 888\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    891\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    892\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    693\u001b[0m )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    304\u001b[0m       placeholder_context\n\u001b[0;32m    305\u001b[0m   )\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file02enocf3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1380\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1381\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     )\n\u001b[0;32m   1383\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1384\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1386\u001b[0m     outputs,\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1388\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1389\u001b[0m )\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   4067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   4068\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 4069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1373\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1373\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1150\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;66;03m# Run forward pass.\u001b[39;00m\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m-> 1150\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1151\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:590\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    588\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\sequential.py:398\u001b[0m, in \u001b[0;36mSequential.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m outputs \u001b[38;5;241m=\u001b[39m inputs  \u001b[38;5;66;03m# handle the corner case where self.layers is empty\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# During each iteration, `inputs` are the inputs to `layer`, and\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# end of each iteration `inputs` is set to `outputs` to prepare for\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# the next layer.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\functional.py:515\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\functional.py:672\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 672\u001b[0m outputs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mlayer(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    674\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    676\u001b[0m     node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)\n\u001b[0;32m    677\u001b[0m ):\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m inputs, initial_state, constants \u001b[38;5;241m=\u001b[39m rnn_utils\u001b[38;5;241m.\u001b[39mstandardize_args(\n\u001b[0;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_constants\n\u001b[0;32m    553\u001b[0m )\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# input_spec to include them.\u001b[39;00m\n\u001b[0;32m    562\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:749\u001b[0m, in \u001b[0;36mLSTM.call\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    735\u001b[0m                 (\n\u001b[0;32m    736\u001b[0m                     last_output,\n\u001b[0;32m    737\u001b[0m                     outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    740\u001b[0m                     runtime,\n\u001b[0;32m    741\u001b[0m                 ) \u001b[38;5;241m=\u001b[39m standard_lstm(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnormal_lstm_kwargs)\n\u001b[0;32m    742\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    743\u001b[0m             (\n\u001b[0;32m    744\u001b[0m                 last_output,\n\u001b[0;32m    745\u001b[0m                 outputs,\n\u001b[0;32m    746\u001b[0m                 new_h,\n\u001b[0;32m    747\u001b[0m                 new_c,\n\u001b[0;32m    748\u001b[0m                 runtime,\n\u001b[1;32m--> 749\u001b[0m             ) \u001b[38;5;241m=\u001b[39m lstm_with_backend_selection(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnormal_lstm_kwargs)\n\u001b[0;32m    751\u001b[0m     states \u001b[38;5;241m=\u001b[39m [new_h, new_c]\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful:\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:1339\u001b[0m, in \u001b[0;36mlstm_with_backend_selection\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     defun_gpu_lstm \u001b[38;5;241m=\u001b[39m gru_lstm_utils\u001b[38;5;241m.\u001b[39mgenerate_defun_backend(\n\u001b[0;32m   1331\u001b[0m         api_name,\n\u001b[0;32m   1332\u001b[0m         gru_lstm_utils\u001b[38;5;241m.\u001b[39mGPU_DEVICE_NAME,\n\u001b[0;32m   1333\u001b[0m         gpu_lstm_with_fallback,\n\u001b[0;32m   1334\u001b[0m         supportive_attribute,\n\u001b[0;32m   1335\u001b[0m     )\n\u001b[0;32m   1337\u001b[0m     \u001b[38;5;66;03m# Call the normal LSTM impl and register the cuDNN impl function. The\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m     \u001b[38;5;66;03m# grappler will kick in during session execution to optimize the graph.\u001b[39;00m\n\u001b[1;32m-> 1339\u001b[0m     last_output, outputs, new_h, new_c, runtime \u001b[38;5;241m=\u001b[39m defun_standard_lstm(\n\u001b[0;32m   1340\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m   1341\u001b[0m     )\n\u001b[0;32m   1342\u001b[0m     gru_lstm_utils\u001b[38;5;241m.\u001b[39mfunction_register(defun_gpu_lstm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m last_output, outputs, new_h, new_c, runtime\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 888\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    891\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    892\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    693\u001b[0m )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:303\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    299\u001b[0m placeholder_context \u001b[38;5;241m=\u001b[39m trace_type\u001b[38;5;241m.\u001b[39mInternalPlaceholderContext(\n\u001b[0;32m    300\u001b[0m     func_graph, type_context\u001b[38;5;241m.\u001b[39mget_placeholder_mapping()\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m--> 303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder_arguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m      \u001b[49m\u001b[43mplaceholder_context\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[0;32m    310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    311\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    312\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mpython_function,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m     create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    320\u001b[0m )\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:356\u001b[0m, in \u001b[0;36mFunctionType.placeholder_arguments\u001b[1;34m(self, placeholder_context)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not generate placeholder value for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    354\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartially defined function type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    355\u001b[0m   placeholder_context\u001b[38;5;241m.\u001b[39mupdate_naming_scope(parameter\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 356\u001b[0m   arguments[parameter\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43mparameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m      \u001b[49m\u001b[43mplaceholder_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mBoundArguments(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:1022\u001b[0m, in \u001b[0;36mTensorSpec.placeholder_value\u001b[1;34m(self, placeholder_context)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     placeholder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_placeholder(context_graph, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1022\u001b[0m   placeholder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_placeholder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1025\u001b[0m   \u001b[38;5;66;03m# Record the requested/user-specified name in case it's different than\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m   \u001b[38;5;66;03m# the uniquified name, for validation when exporting signatures.\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m   placeholder\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39m_set_attr(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_user_specified_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1029\u001b[0m       attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(s\u001b[38;5;241m=\u001b[39mcompat\u001b[38;5;241m.\u001b[39mas_bytes(name)))\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:1060\u001b[0m, in \u001b[0;36mTensorSpec._graph_placeholder\u001b[1;34m(self, graph, name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m: shape}\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1060\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m   1061\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlaceholder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1064\u001b[0m   \u001b[38;5;66;03m# TODO(b/262413656) Sometimes parameter names are not valid op names, in\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m   \u001b[38;5;66;03m# which case an unnamed placeholder is created instead. Update this logic\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m   \u001b[38;5;66;03m# to sanitize the name instead of falling back on unnamed placeholders.\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarning(e)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2652\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   2649\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   2650\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   2651\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 2652\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2654\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2655\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2656\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2657\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2658\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2659\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2660\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2661\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2662\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   2663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1160\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(g)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\NUS\\Fintech-Hacka\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1017\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1013\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[0;32m   1014\u001b[0m                                          serialized)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1017\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1019\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTMPrediction(dataseparate, end_date='2023-12-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN:  1\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 88ms/step - loss: 0.0520 - val_loss: 0.0076\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0012\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 4.9890e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 5.7228e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 7.4540e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.8004e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.8617e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 5.4074e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.7117e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.3530e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.5440e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.2936e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.2622e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.2616e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.2376e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 6.1023e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 7.2982e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.3251e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 5.3038e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 5.1501e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.3668e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 5.0128e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 4.9217e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 4.8706e-04\n",
      "1/1 [==============================] - 1s 784ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2238.37\n",
      "RUN:  2\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 88ms/step - loss: 0.0515 - val_loss: 0.0121\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0011\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 5.1625e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 5.0576e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 6.1100e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.8156e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.2494e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.5854e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.3959e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 5.2455e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.3685e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.3152e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.3643e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 7.2852e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 6.1075e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.4948e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.2212e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 6.9720e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 4.9979e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.0494e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0307e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 6.5665e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 6.1176e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 4.9713e-04\n",
      "1/1 [==============================] - 1s 741ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2253.323\n",
      "RUN:  3\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 88ms/step - loss: 0.0476 - val_loss: 0.0041\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 6.2775e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 5.5277e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.1354e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.5108e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.3612e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.2561e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.2335e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.8691e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.9219e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 5.1299e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 6.5825e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.1048e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 7.6034e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 6.9842e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 6.1297e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.1178e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 4.9714e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 5.8790e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 8.3080e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 6.7269e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 4.9313e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 4.8366e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 5.0639e-04\n",
      "1/1 [==============================] - 1s 754ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2204.6196\n",
      "RUN:  4\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 92ms/step - loss: 0.0522 - val_loss: 0.0045\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0019\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 6.3268e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 4.7761e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 8.4196e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 7.0770e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 7.5882e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 6.3402e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.8124e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.5470e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.3467e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 7.1947e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.1281e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0942e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0490e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 5.3077e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 6.0369e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 6.0739e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 7.0145e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 6.2978e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.8908e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 4.8271e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 5.6530e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 4.8543e-04\n",
      "1/1 [==============================] - 1s 733ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2214.1958\n",
      "RUN:  5\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 89ms/step - loss: 0.0556 - val_loss: 0.0089\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 6.1937e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 5.1019e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 5.4086e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 7.3256e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 5.9115e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 6.2897e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.5926e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.4062e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 6.6811e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.5469e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.4752e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.6217e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.3086e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.7542e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 6.5397e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 8.8175e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.1637e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.1029e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.1643e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 5.1020e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 5.0964e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 5.4236e-04\n",
      "1/1 [==============================] - 1s 738ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2202.1409\n",
      "RUN:  6\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 91ms/step - loss: 0.0436 - val_loss: 0.0073\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 5.7439e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 6.3053e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 5.4339e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 7.0338e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.6915e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 6.9386e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.2973e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.8657e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 5.8090e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 5.3190e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.2881e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 6.3525e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.7258e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 6.3298e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.5703e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.2641e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 6.0860e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0739e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.8252e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 5.1072e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 4.9778e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 4.8389e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0650e-04\n",
      "1/1 [==============================] - 1s 732ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2252.322\n",
      "RUN:  7\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 88ms/step - loss: 0.0441 - val_loss: 0.0039\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 6.9315e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 6.2570e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 4.7300e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 8.6912e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 9.6580e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 5.0107e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.5496e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 6.8607e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 6.7979e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.2276e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.5278e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 6.2232e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.1889e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 8.8892e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.4698e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 9.6284e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 5.8346e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 5.8915e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 6.1416e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 4.8216e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 4.7868e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 4.7847e-04\n",
      "1/1 [==============================] - 1s 732ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2223.1462\n",
      "RUN:  8\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 90ms/step - loss: 0.0524 - val_loss: 0.0078\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0012\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 4.9101e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 5.3735e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 7.9983e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.2095e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.7395e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 7.3834e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.0908e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.0664e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.0201e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 6.1497e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.2357e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.0450e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.2519e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 4.9707e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 6.3851e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 5.0307e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 6.3957e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.2047e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 6.1217e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 4.7530e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 8.2557e-04\n",
      "1/1 [==============================] - 1s 733ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2339.2974\n",
      "RUN:  9\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 86ms/step - loss: 0.0590 - val_loss: 0.0164\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0012\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 5.0569e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 6.4123e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 7.5240e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 6.0145e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.7821e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 6.3722e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.5595e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.1842e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 6.9131e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.1075e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 6.1261e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.1464e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.2321e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 8.0198e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.1290e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0476e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0601e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.5022e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 5.0521e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 5.1442e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.0473e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.5588e-04\n",
      "1/1 [==============================] - 1s 753ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2275.7607\n",
      "RUN:  10\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 87ms/step - loss: 0.0428 - val_loss: 0.0114\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 7.5705e-04\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 6.5344e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 6.3259e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.6504e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.7757e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 6.5990e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 6.4346e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 6.4783e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.6267e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.5153e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 6.2611e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.7212e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.3990e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.4928e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.3730e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.6375e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.3030e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.2236e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.8706e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.2244e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.6026e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 5.1137e-04\n",
      "1/1 [==============================] - 1s 758ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2256.3452\n",
      "RUN:  11\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 88ms/step - loss: 0.0507 - val_loss: 0.0074\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 5.8084e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 5.4832e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 5.9790e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 5.3450e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.6311e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.9612e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.5635e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.8345e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.4632e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.5729e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 6.3229e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.6600e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.5859e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 6.5990e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.3977e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.7077e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.2196e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.7824e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.1324e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0107e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 5.4904e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 4.9193e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 5.8564e-04\n",
      "1/1 [==============================] - 1s 725ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2296.133\n",
      "RUN:  12\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 5s 97ms/step - loss: 0.0407 - val_loss: 0.0025\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 6.6905e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 4.7626e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 5.1838e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 7.9927e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.9258e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.0343e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 5.3390e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.2265e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.1795e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 5.6859e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 5.4865e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.2077e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.6497e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 6.8341e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 5.9754e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 5.1229e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 6.5983e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.0023e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 5.1137e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 4.8698e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 5.2212e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 4.7613e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 6.2009e-04\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2174.7817\n",
      "RUN:  13\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 91ms/step - loss: 0.0407 - val_loss: 0.0072\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 8.0826e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 4.9713e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 4.9717e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.5975e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.2291e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.3223e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.8924e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.2645e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 7.5337e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 6.2543e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 8.3474e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.1080e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.1490e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 5.6632e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 6.7252e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 5.4638e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 4.9464e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 6.3827e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 7.3020e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 4.9500e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 4.8268e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 4.8249e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 4.7058e-04\n",
      "1/1 [==============================] - 1s 793ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2214.7832\n",
      "RUN:  14\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 91ms/step - loss: 0.0611 - val_loss: 0.0152\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0023\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 5.3908e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 5.7358e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 6.4789e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 5.3146e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.7217e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.1566e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.1959e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.4491e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 6.6613e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.5904e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 6.1730e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.0960e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.6001e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.1874e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.3274e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 6.4122e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.7041e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 5.0274e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0248e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.5508e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 4.8744e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 4.8835e-04\n",
      "1/1 [==============================] - 1s 795ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2232.2144\n",
      "RUN:  15\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 10s 105ms/step - loss: 0.0549 - val_loss: 0.0136\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 9.8661e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 5.7095e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 5.2292e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 9.2443e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 5.2405e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 5.3446e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 5.3769e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 7.8728e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.2878e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.3987e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.4448e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 6.5012e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 5.6907e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 5.8365e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 7.5926e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 5.8920e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.6271e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 5.5617e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.0631e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 5.6715e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 5.6206e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0024 - val_loss: 4.9546e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 5.1433e-04\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2266.5188\n",
      "RUN:  16\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 7s 143ms/step - loss: 0.0626 - val_loss: 0.0140\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 6.7808e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 5.4025e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.4484e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.5133e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 6.7545e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 5.3446e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 5.7738e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.2604e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.3162e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.2796e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 6.6090e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 6.6082e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.4039e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.2966e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.4188e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.1215e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.2589e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.2282e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.0585e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.2529e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 6.1161e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0024 - val_loss: 5.5169e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.2302e-04\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2252.6194\n",
      "RUN:  17\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 6s 141ms/step - loss: 0.0464 - val_loss: 0.0050\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0023\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0035 - val_loss: 5.0133e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 5.3966e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 9.3669e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 5.8999e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.4565e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.2891e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.9288e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.4806e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.4672e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.3516e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.2884e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.3162e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 5.7272e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 6.0334e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 6.3796e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.0916e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 7.2965e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 5.4549e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.6314e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.1929e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 5.6837e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 4.9471e-04\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2227.8477\n",
      "RUN:  18\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 6s 131ms/step - loss: 0.0464 - val_loss: 0.0068\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 5.9442e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0042 - val_loss: 8.4455e-04\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0030 - val_loss: 5.3244e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 5.5819e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.2182e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.6553e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.7635e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.6417e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.3014e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.5953e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.4901e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 5.9506e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 5.2570e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 9.4227e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 7.4670e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 5.2253e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0026 - val_loss: 4.9259e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0024 - val_loss: 6.2641e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0025 - val_loss: 5.0636e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 4.8870e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.0895e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 5.0410e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 4.8496e-04\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2218.677\n",
      "RUN:  19\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 5s 97ms/step - loss: 0.0459 - val_loss: 0.0051\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 8.0844e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 8.8747e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 5.6753e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 6.6111e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 5.7653e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.8814e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 5.6609e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.6632e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 5.7984e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 6.2228e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 6.6462e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 5.5604e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.6175e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 5.5901e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 5.5065e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 5.8963e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 6.4291e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.3621e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 5.2526e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 5.6587e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 5.2517e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 5.3251e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 5.7683e-04\n",
      "1/1 [==============================] - 1s 775ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2279.0073\n",
      "RUN:  20\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 5s 96ms/step - loss: 0.0507 - val_loss: 0.0088\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 6.3106e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 7.4765e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.5426e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.3130e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.7097e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 6.0725e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.4057e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.4580e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 5.3825e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.3232e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 6.6990e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.3583e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 6.7050e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 6.0168e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.5405e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.8159e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.3237e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 5.0365e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 6.8416e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 5.3291e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 4.9450e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 7.8114e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.0888e-04\n",
      "1/1 [==============================] - 1s 771ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2262.8298\n",
      "RUN:  21\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 96ms/step - loss: 0.0580 - val_loss: 0.0113\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 6.0014e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 6.7281e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 5.2851e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 9.3274e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.1740e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.2945e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 8.0308e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.1307e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 6.2985e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.3265e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.5154e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.0712e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.2428e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.1656e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 5.4379e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.5880e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 6.6494e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.3477e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 6.5454e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.3538e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.0865e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 4.9619e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 4.7884e-04\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2243.4136\n",
      "RUN:  22\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 89ms/step - loss: 0.0651 - val_loss: 0.0165\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0024\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 4.8572e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 6.0089e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0030 - val_loss: 7.0185e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.1383e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.3451e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.5357e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.2956e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 5.6709e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.4472e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 8.7184e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.3308e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.3688e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.1721e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.6449e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 6.0082e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.6445e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.0972e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.0244e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 5.6233e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.9629e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 5.0153e-04\n",
      "1/1 [==============================] - 1s 774ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2223.3086\n",
      "RUN:  23\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 5s 95ms/step - loss: 0.0617 - val_loss: 0.0208\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0017\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0044 - val_loss: 6.3607e-04\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 8.5635e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 6.1247e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 5.9007e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 6.0502e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 5.9333e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0028 - val_loss: 6.0076e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 5.7184e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 6.3005e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 6.1088e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 5.7853e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 6.0486e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.9952e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0026 - val_loss: 5.7557e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.9062e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.4694e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 5.6614e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.3662e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 5.4088e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.3132e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 6.5581e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 5.9401e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 5.7778e-04\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2203.4634\n",
      "RUN:  24\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 98ms/step - loss: 0.0326 - val_loss: 0.0029\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 9.4911e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0042 - val_loss: 6.0602e-04\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 5.7247e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 5.4078e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.4653e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.3514e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 6.4159e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 6.2837e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 5.2981e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 6.6019e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.2867e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 5.2623e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.2717e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 6.0224e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 7.5828e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.2825e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.0565e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.1698e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.1961e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 4.9949e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 7.1213e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 8.2806e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 9.0461e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 6.6855e-04\n",
      "1/1 [==============================] - 1s 819ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2165.0308\n",
      "RUN:  25\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 97ms/step - loss: 0.0400 - val_loss: 0.0057\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 6.2797e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 9.1599e-04\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 5.8243e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.7977e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.7282e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 6.1415e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 6.9263e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 5.7620e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.8256e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.5823e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 7.9032e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 6.3359e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.7024e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 6.1867e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 6.2066e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.6712e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.3918e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 5.5503e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.4800e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 5.6991e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 5.9756e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 5.4481e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 5.1998e-04\n",
      "1/1 [==============================] - 1s 801ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2225.3096\n",
      "RUN:  26\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 95ms/step - loss: 0.0726 - val_loss: 0.0231\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0188 - val_loss: 0.0019\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 4.9012e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0033 - val_loss: 5.9462e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 9.9050e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 5.8430e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.7435e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 7.2802e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 7.6866e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 5.3271e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 6.2348e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 5.3708e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 5.4878e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.3765e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.5336e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 5.3038e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.1991e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 5.2550e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 6.4516e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.0086e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.0540e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 4.9622e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 6.0877e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 6.1676e-04\n",
      "1/1 [==============================] - 1s 815ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2293.4043\n",
      "RUN:  27\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 7s 144ms/step - loss: 0.0516 - val_loss: 0.0104\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0017\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 5.8291e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 5.1167e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 6.8977e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.0870e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.0041e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 6.1576e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.4758e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.2847e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.9404e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 5.7062e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 5.3663e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.2717e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.2373e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.7431e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 5.4069e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.6854e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 5.0170e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 5.7711e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 4.7669e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.0156e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 7.0623e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 4.6463e-04\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2250.675\n",
      "RUN:  28\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 7s 130ms/step - loss: 0.0518 - val_loss: 0.0091\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 5.9545e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 5.2480e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 5.3218e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.1244e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 5.1771e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 5.4995e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 6.3275e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 8.6171e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 6.6561e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 6.1606e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 5.5629e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.4763e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.6924e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 5.2124e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.5015e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 5.0633e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.0183e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 5.0452e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 5.7308e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 5.3712e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 5.9605e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 5.1221e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 4.9333e-04\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2239.7239\n",
      "RUN:  29\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 6s 128ms/step - loss: 0.0454 - val_loss: 0.0041\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 8.3503e-04\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 6.2186e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.7248e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.1818e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.2402e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.3719e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.2838e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.8151e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 6.0368e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 5.2711e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.4025e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.8741e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.0963e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 7.0245e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 7.0127e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.2895e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 5.4380e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 5.6213e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 4.8350e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.3378e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 4.6824e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 4.7896e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 5.2108e-04\n",
      "1/1 [==============================] - 1s 753ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2213.0825\n",
      "RUN:  30\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 89ms/step - loss: 0.0542 - val_loss: 0.0089\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0034\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 5.3148e-04\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 6.9299e-04\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 9.4897e-04\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 5.7935e-04\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.6603e-04\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 6.5934e-04\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 8.9604e-04\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.7224e-04\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.5540e-04\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.4626e-04\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.8200e-04\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 5.5448e-04\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 5.7322e-04\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 6.1292e-04\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.9692e-04\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 5.2379e-04\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 5.1262e-04\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 5.9197e-04\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 5.3374e-04\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 6.2140e-04\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 4.9933e-04\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 6.8305e-04\n",
      "1/1 [==============================] - 1s 755ms/step\n",
      "Prediction for:  2023-12-20         CLOSE:  2311.894\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "63.93540852864583"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataindex = datadf[['Close', 'Open', 'High', 'Low', 'Volume', 'Sentiment']]\n",
    "LSTMPrediction(dataindex, end_date='2023-12-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearningEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
