{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\MachineLearningEnv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation,concatenate, Attention, Bidirectional,GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.layers import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pull and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-11'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#end_date = '2024-01-08'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m display(end_date)\n\u001b[1;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43myf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mETH-USD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Displays till yesterday as today is not complete\u001b[39;00m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      8\u001b[0m dates \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\MachineLearningEnv\\Lib\\site-packages\\yfinance\\utils.py:103\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 103\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\MachineLearningEnv\\Lib\\site-packages\\yfinance\\multi.py:163\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, show_errors, interval, prepost, proxy, rounding, timeout, session)\u001b[0m\n\u001b[0;32m    156\u001b[0m         _download_one_threaded(ticker, period\u001b[38;5;241m=\u001b[39mperiod, interval\u001b[38;5;241m=\u001b[39minterval,\n\u001b[0;32m    157\u001b[0m                                start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, prepost\u001b[38;5;241m=\u001b[39mprepost,\n\u001b[0;32m    158\u001b[0m                                actions\u001b[38;5;241m=\u001b[39mactions, auto_adjust\u001b[38;5;241m=\u001b[39mauto_adjust,\n\u001b[0;32m    159\u001b[0m                                back_adjust\u001b[38;5;241m=\u001b[39mback_adjust, repair\u001b[38;5;241m=\u001b[39mrepair, keepna\u001b[38;5;241m=\u001b[39mkeepna,\n\u001b[0;32m    160\u001b[0m                                progress\u001b[38;5;241m=\u001b[39m(progress \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[0;32m    161\u001b[0m                                rounding\u001b[38;5;241m=\u001b[39mrounding, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared\u001b[38;5;241m.\u001b[39m_DFS) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[1;32m--> 163\u001b[0m         \u001b[43m_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_date = '2016-01-01'\n",
    "today = datetime.now()\n",
    "end_date = datetime.strftime(today, '%Y-%m-%d')\n",
    "#end_date = '2024-01-08'\n",
    "display(end_date)\n",
    "data = yf.download(\"ETH-USD\", start=start_date, end=end_date) #Displays till yesterday as today is not complete\n",
    "data = data.reset_index()\n",
    "dates = data['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataclose = data.reset_index()['Close']\n",
    "plt.plot(dataclose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "dataclose = scaler.fit_transform(np.array(dataclose).reshape(-1,1))\n",
    "dataclose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataclose)*0.6)\n",
    "test_size = len(dataclose) - train_size\n",
    "train_data,test_data = dataclose[0:train_size,:],dataclose[train_size:len(dataclose),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step = 1):\n",
    "    dataX,dataY = [],[]\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "                   a = dataset[i:(i+time_step),0]\n",
    "                   dataX.append(a)\n",
    "                   dataY.append(dataset[i + time_step,0])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the create dataset function to split the data into \n",
    "# input output datasets with time step 100\n",
    "time_step = 100\n",
    "X_train,Y_train =  create_dataset(train_data,time_step)\n",
    "X_test,Y_test =  create_dataset(test_data,time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50,return_sequences = True,input_shape = (X_train.shape[1],1)))\n",
    "model.add(LSTM(50,return_sequences = True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error',optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,Y_train,validation_data = (X_test,Y_test),epochs = 50,batch_size = 64,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.sqrt(mean_squared_error(Y_train,train_predict)) / Y_train.shape[0])\n",
    "print(math.sqrt(mean_squared_error(Y_test,test_predict)) / Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredictPlot = np.empty_like(dataclose)\n",
    "trainPredictPlot[:,:] = np.nan\n",
    "trainPredictPlot[look_back : len(train_predict)+look_back,:] = train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredictPlot = np.empty_like(dataclose)\n",
    "testPredictPlot[:,:] = np.nan\n",
    "testPredictPlot[len(train_predict)+(look_back)*2 + 1 : len(dataclose) - 1,:] = test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scaler.inverse_transform(dataclose))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = np.array(dataclose[-100:]).transpose()\n",
    "prediction = scaler.inverse_transform(model.predict(prediction_data))[0][0]\n",
    "print(\"Prediction for: \", end_date, \"        CLOSE: \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "runs = 100\n",
    "for i in range(runs):\n",
    "    print(\"RUN: \", i+1)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50,return_sequences = True,input_shape = (X_train.shape[1],1)))\n",
    "    model.add(LSTM(50,return_sequences = True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss = 'mean_squared_error',optimizer = 'adam')\n",
    "    model.fit(X_train,Y_train,validation_data = (X_test,Y_test),epochs = 10,batch_size = 64,verbose = 1)\n",
    "    prediction = scaler.inverse_transform(model.predict(prediction_data))[0][0]\n",
    "    print(\"Prediction for: \", end_date, \"        CLOSE: \", prediction)\n",
    "    results.append(prediction)\n",
    "\n",
    "plt.hist(results)\n",
    "mu, std = norm.fit(data)\n",
    "xmin, xmax = plt.xlim() \n",
    "x = np.linspace(xmin, xmax, 100) \n",
    "p = norm.pdf(x, mu, std) \n",
    "  \n",
    "plt.plot(x, p, 'k', linewidth=2) \n",
    "title = \"Fit Values: {:.2f} and {:.2f}\".format(mu, std) \n",
    "plt.title(title)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTMPrediction(datafile = 'lstm_data.csv', time_step = 10, runs = 30):\n",
    "\n",
    "    datadf = pd.read_csv(datafile)[-700:]\n",
    "    yest = (np.array(datadf['Date'])[-1])\n",
    "    yest=datetime.strptime(yest,'%Y-%m-%d')\n",
    "    end_date=yest+timedelta(1)\n",
    "    end_date = datetime.strftime(end_date, '%Y-%m-%d')\n",
    "    training_df = datadf[['Close', 'Open', 'High', 'Low', 'Volume', 'Sentiment']]\n",
    "\n",
    "    #Data Scaling\n",
    "    Xscaler = MinMaxScaler()\n",
    "    Xdata = Xscaler.fit_transform(np.array(training_df))\n",
    "    Xdata.shape\n",
    "    Yscaler = MinMaxScaler()\n",
    "    Ydata = Yscaler.fit_transform(np.array([training_df['Close']]).transpose())\n",
    "\n",
    "    Xtrain_data, Xtest_data = train_test_split(Xdata, test_size=0.3, shuffle=False)\n",
    "    Ytrain_data, Ytest_data = train_test_split(Ydata, test_size=0.3, shuffle=False)\n",
    "    \n",
    "    def build_timeseries(Xdata, Ydata, time_step):\n",
    "        dim_0 = Xdata.shape[0] - time_step\n",
    "        dim_1 = Xdata.shape[1]\n",
    "\n",
    "        x = np.zeros((dim_0, time_step, dim_1))\n",
    "        y = np.zeros((Ydata.shape[0] - time_step,))\n",
    "\n",
    "        for i in range(dim_0):\n",
    "            x[i] = Xdata[i:time_step+i]\n",
    "            y[i] = Ydata[time_step+i]\n",
    "        return x, y\n",
    "\n",
    "    \n",
    "    X_train, Y_train = build_timeseries(Xtrain_data, Ytrain_data.transpose()[0], time_step)\n",
    "    X_test, Y_test = build_timeseries(Xtest_data, Ytest_data.transpose()[0], time_step)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], time_step, X_train.shape[2]))\n",
    "    X_test = X_test.reshape((X_test.shape[0], time_step, X_test.shape[2]))\n",
    "\n",
    "    results = []\n",
    "    prediction_data = np.array([X_test[-1]])\n",
    "    for i in range(runs):\n",
    "        print(\"RUN: \", i+1)\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50,return_sequences = True,input_shape = (X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(LSTM(50,return_sequences = True))\n",
    "        model.add(LSTM(50,return_sequences = True))\n",
    "        model.add(GlobalAveragePooling1D())\n",
    "        model.add(Dense(25,activation='relu'))\n",
    "        model.add(Dense(25))\n",
    "        model.compile(loss = 'mean_squared_error',optimizer = 'adam')\n",
    "        lstm_model = model.fit(X_train,Y_train,validation_data = (X_test,Y_test),epochs = 25,batch_size = 64, verbose = 1)\n",
    "        prediction = model.predict(prediction_data)\n",
    "        prediction = Yscaler.inverse_transform(prediction)[0][0]\n",
    "        print(\"Prediction for: \", end_date, \"        CLOSE: \", prediction)\n",
    "        results.append(prediction)\n",
    "\n",
    "    lastclose = Yscaler.inverse_transform([Ydata[-1]])[0][0]\n",
    "    adjresults = np.array([x - lastclose for x in results])\n",
    "    mu = adjresults.mean()\n",
    "    std = adjresults.std()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    xmin, xmax = plt.xlim()\n",
    "    diff = pd.DataFrame(adjresults) \n",
    "    kde = diff.plot.kde(ax=ax, legend = False)\n",
    "    diff.plot.hist(density=True, ax=ax, bins=20)\n",
    "    title = \"Fit Values: {:.2f} and {:.2f}\".format(mu, std) \n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    #Returns average change in price\n",
    "    return mu, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN:  1\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\MachineLearningEnv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\MachineLearningEnv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\MachineLearningEnv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "8/8 [==============================] - 6s 147ms/step - loss: 0.1423 - val_loss: 0.1146\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1211 - val_loss: 0.0844\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0960 - val_loss: 0.0624\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0741 - val_loss: 0.0460\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0538 - val_loss: 0.0305\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0349 - val_loss: 0.0199\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0245 - val_loss: 0.0132\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0064\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0041\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0032\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0016\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0018\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "1/1 [==============================] - 1s 905ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2287.6184\n",
      "RUN:  2\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 5s 173ms/step - loss: 0.1434 - val_loss: 0.1148\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1183 - val_loss: 0.0792\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0885 - val_loss: 0.0590\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0686 - val_loss: 0.0429\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0483 - val_loss: 0.0304\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0348 - val_loss: 0.0218\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0257 - val_loss: 0.0146\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0178 - val_loss: 0.0087\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0049\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0029\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0019\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "1/1 [==============================] - 1s 931ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2335.008\n",
      "RUN:  3\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 5s 145ms/step - loss: 0.1407 - val_loss: 0.1091\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1107 - val_loss: 0.0688\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0778 - val_loss: 0.0394\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0504 - val_loss: 0.0214\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0275 - val_loss: 0.0098\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0073\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0035\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0020\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0022\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0016\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "1/1 [==============================] - 1s 835ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2307.6882\n",
      "RUN:  4\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 5s 144ms/step - loss: 0.1448 - val_loss: 0.1202\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1273 - val_loss: 0.0950\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1029 - val_loss: 0.0688\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0777 - val_loss: 0.0505\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0571 - val_loss: 0.0363\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0414 - val_loss: 0.0249\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0287 - val_loss: 0.0149\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0188 - val_loss: 0.0081\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0040\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0026\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.0019\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0018\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0015\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0015\n",
      "1/1 [==============================] - 1s 848ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2270.4438\n",
      "RUN:  5\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 5s 131ms/step - loss: 0.1367 - val_loss: 0.0980\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0937 - val_loss: 0.0546\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0628 - val_loss: 0.0348\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0416 - val_loss: 0.0208\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0243 - val_loss: 0.0123\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0153 - val_loss: 0.0067\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0036\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0071 - val_loss: 0.0019\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0014\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027EA7793A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 835ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2265.1584\n",
      "RUN:  6\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 6s 154ms/step - loss: 0.1379 - val_loss: 0.1025\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1018 - val_loss: 0.0660\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0752 - val_loss: 0.0477\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0557 - val_loss: 0.0346\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0392 - val_loss: 0.0267\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0297 - val_loss: 0.0174\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0215 - val_loss: 0.0117\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0154 - val_loss: 0.0074\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0049\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0029\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0016\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027E98DF4360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 846ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2308.5603\n",
      "RUN:  7\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 5s 139ms/step - loss: 0.1366 - val_loss: 0.0990\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0988 - val_loss: 0.0640\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0746 - val_loss: 0.0452\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0539 - val_loss: 0.0291\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0338 - val_loss: 0.0192\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0219 - val_loss: 0.0103\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0054\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0027\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0028\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0026\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0018\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "1/1 [==============================] - 1s 822ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2226.1482\n",
      "RUN:  8\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 5s 129ms/step - loss: 0.1450 - val_loss: 0.1203\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1294 - val_loss: 0.0998\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1119 - val_loss: 0.0843\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0931 - val_loss: 0.0615\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0680 - val_loss: 0.0452\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0512 - val_loss: 0.0342\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0398 - val_loss: 0.0255\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0294 - val_loss: 0.0175\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0225 - val_loss: 0.0126\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0172 - val_loss: 0.0092\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0067\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0042\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0034\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 0.0019\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.0027\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0016\n",
      "1/1 [==============================] - 1s 800ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2309.6086\n",
      "RUN:  9\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 5s 129ms/step - loss: 0.1408 - val_loss: 0.1086\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1101 - val_loss: 0.0732\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0820 - val_loss: 0.0500\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0591 - val_loss: 0.0327\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0364 - val_loss: 0.0179\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0209 - val_loss: 0.0101\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0042\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0023\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "1/1 [==============================] - 1s 762ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2316.826\n",
      "RUN:  10\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 6s 186ms/step - loss: 0.1396 - val_loss: 0.1036\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1040 - val_loss: 0.0660\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0731 - val_loss: 0.0407\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0474 - val_loss: 0.0248\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0299 - val_loss: 0.0175\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0211 - val_loss: 0.0105\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0051\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0028\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0019\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0020\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0056 - val_loss: 0.0021\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "1/1 [==============================] - 1s 726ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2148.4836\n",
      "RUN:  11\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 5s 117ms/step - loss: 0.1366 - val_loss: 0.0968\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0964 - val_loss: 0.0681\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0762 - val_loss: 0.0496\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0554 - val_loss: 0.0334\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0377 - val_loss: 0.0232\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0260 - val_loss: 0.0139\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0080\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0045\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0028\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0057 - val_loss: 0.0015\n",
      "1/1 [==============================] - 1s 708ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2300.0596\n",
      "RUN:  12\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 4s 133ms/step - loss: 0.1425 - val_loss: 0.1142\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1192 - val_loss: 0.0887\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1011 - val_loss: 0.0735\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0842 - val_loss: 0.0590\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0668 - val_loss: 0.0464\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0523 - val_loss: 0.0355\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0410 - val_loss: 0.0259\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0315 - val_loss: 0.0186\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0235 - val_loss: 0.0128\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0178 - val_loss: 0.0088\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0059\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0039\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0024\n",
      "1/1 [==============================] - 1s 774ms/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2172.4084\n",
      "RUN:  13\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 164ms/step - loss: 0.1443 - val_loss: 0.1182\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1243 - val_loss: 0.0873\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0948 - val_loss: 0.0606\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0701 - val_loss: 0.0426\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0481 - val_loss: 0.0286\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0332 - val_loss: 0.0190\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0225 - val_loss: 0.0110\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0146 - val_loss: 0.0058\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0032\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0021\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0017\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2269.1848\n",
      "RUN:  14\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 206ms/step - loss: 0.1411 - val_loss: 0.1087\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1122 - val_loss: 0.0794\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0885 - val_loss: 0.0582\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0675 - val_loss: 0.0455\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0514 - val_loss: 0.0352\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0401 - val_loss: 0.0259\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0306 - val_loss: 0.0193\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0237 - val_loss: 0.0129\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.0089\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0132 - val_loss: 0.0056\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0042\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0028\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0021\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2350.2712\n",
      "RUN:  15\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 211ms/step - loss: 0.1384 - val_loss: 0.1042\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1056 - val_loss: 0.0743\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0835 - val_loss: 0.0559\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0637 - val_loss: 0.0405\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0450 - val_loss: 0.0282\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0317 - val_loss: 0.0186\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0223 - val_loss: 0.0115\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0159 - val_loss: 0.0079\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0053\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0028\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0023\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2223.17\n",
      "RUN:  16\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 170ms/step - loss: 0.1320 - val_loss: 0.0880\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0860 - val_loss: 0.0538\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0611 - val_loss: 0.0341\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0402 - val_loss: 0.0203\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0249 - val_loss: 0.0142\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0170 - val_loss: 0.0079\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0059\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0026\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0069 - val_loss: 0.0017\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0018\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2311.9927\n",
      "RUN:  17\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 179ms/step - loss: 0.1398 - val_loss: 0.1058\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1069 - val_loss: 0.0761\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0873 - val_loss: 0.0587\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0684 - val_loss: 0.0439\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0496 - val_loss: 0.0325\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0373 - val_loss: 0.0229\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0264 - val_loss: 0.0146\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0179 - val_loss: 0.0083\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0045\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0024\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2283.8274\n",
      "RUN:  18\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 190ms/step - loss: 0.1458 - val_loss: 0.1216\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1315 - val_loss: 0.1054\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1176 - val_loss: 0.0917\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1029 - val_loss: 0.0795\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0888 - val_loss: 0.0685\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0767 - val_loss: 0.0573\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0658 - val_loss: 0.0473\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0554 - val_loss: 0.0393\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0461 - val_loss: 0.0309\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0377 - val_loss: 0.0251\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0314 - val_loss: 0.0191\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0252 - val_loss: 0.0149\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0204 - val_loss: 0.0113\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0166 - val_loss: 0.0086\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0065\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0044\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 0.0030\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0024\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0019\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0026\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0018\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2344.76\n",
      "RUN:  19\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 8s 226ms/step - loss: 0.1458 - val_loss: 0.1213\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1287 - val_loss: 0.0951\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0993 - val_loss: 0.0604\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0680 - val_loss: 0.0359\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0395 - val_loss: 0.0164\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0193 - val_loss: 0.0070\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0041\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0021\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0024\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0029\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2174.8809\n",
      "RUN:  20\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 8s 197ms/step - loss: 0.1394 - val_loss: 0.1084\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1094 - val_loss: 0.0740\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0852 - val_loss: 0.0471\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0554 - val_loss: 0.0258\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0316 - val_loss: 0.0130\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0175 - val_loss: 0.0084\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0113 - val_loss: 0.0038\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0018\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0046 - val_loss: 0.0014\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2272.8823\n",
      "RUN:  21\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 8s 197ms/step - loss: 0.1401 - val_loss: 0.1082\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1054 - val_loss: 0.0644\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0744 - val_loss: 0.0436\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0520 - val_loss: 0.0316\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0371 - val_loss: 0.0243\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0282 - val_loss: 0.0170\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0217 - val_loss: 0.0125\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0161 - val_loss: 0.0080\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0124 - val_loss: 0.0055\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0034\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0024\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0027\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2271.5435\n",
      "RUN:  22\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 188ms/step - loss: 0.1430 - val_loss: 0.1149\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1176 - val_loss: 0.0796\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0838 - val_loss: 0.0494\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0571 - val_loss: 0.0339\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0376 - val_loss: 0.0229\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0270 - val_loss: 0.0146\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0179 - val_loss: 0.0086\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0049\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0016\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2254.789\n",
      "RUN:  23\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 191ms/step - loss: 0.1453 - val_loss: 0.1198\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1282 - val_loss: 0.0940\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1048 - val_loss: 0.0758\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0863 - val_loss: 0.0609\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0666 - val_loss: 0.0467\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0518 - val_loss: 0.0348\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0383 - val_loss: 0.0223\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0260 - val_loss: 0.0138\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0176 - val_loss: 0.0084\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0050\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0031\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0021\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0014\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2307.1284\n",
      "RUN:  24\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 204ms/step - loss: 0.1438 - val_loss: 0.1167\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1207 - val_loss: 0.0824\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0929 - val_loss: 0.0600\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0699 - val_loss: 0.0410\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0476 - val_loss: 0.0232\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0272 - val_loss: 0.0131\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0165 - val_loss: 0.0073\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0035\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0020\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0022\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2190.5398\n",
      "RUN:  25\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 8s 207ms/step - loss: 0.1411 - val_loss: 0.1098\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1109 - val_loss: 0.0672\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0759 - val_loss: 0.0452\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0553 - val_loss: 0.0338\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0386 - val_loss: 0.0227\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0266 - val_loss: 0.0155\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0196 - val_loss: 0.0100\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0064\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0085 - val_loss: 0.0033\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0072 - val_loss: 0.0030\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0021\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0019\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0018\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2269.0874\n",
      "RUN:  26\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 198ms/step - loss: 0.1439 - val_loss: 0.1167\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1210 - val_loss: 0.0825\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0906 - val_loss: 0.0603\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0727 - val_loss: 0.0464\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0542 - val_loss: 0.0342\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0397 - val_loss: 0.0259\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0300 - val_loss: 0.0175\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0209 - val_loss: 0.0109\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0071\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0105 - val_loss: 0.0040\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0079 - val_loss: 0.0024\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0021\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0018\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2247.2666\n",
      "RUN:  27\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 184ms/step - loss: 0.1398 - val_loss: 0.1058\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1077 - val_loss: 0.0715\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0815 - val_loss: 0.0529\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0604 - val_loss: 0.0388\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0432 - val_loss: 0.0273\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0297 - val_loss: 0.0156\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0173 - val_loss: 0.0067\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0030\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0071 - val_loss: 0.0023\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0014\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2320.3135\n",
      "RUN:  28\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 192ms/step - loss: 0.1418 - val_loss: 0.1127\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1158 - val_loss: 0.0787\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0823 - val_loss: 0.0466\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0539 - val_loss: 0.0281\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0326 - val_loss: 0.0174\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0208 - val_loss: 0.0094\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0128 - val_loss: 0.0052\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0086 - val_loss: 0.0029\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0022\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0014\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2276.415\n",
      "RUN:  29\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 190ms/step - loss: 0.1459 - val_loss: 0.1200\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1282 - val_loss: 0.0971\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1092 - val_loss: 0.0826\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0938 - val_loss: 0.0677\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0732 - val_loss: 0.0462\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0504 - val_loss: 0.0328\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0369 - val_loss: 0.0216\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0249 - val_loss: 0.0126\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0162 - val_loss: 0.0068\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0035\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2305.3857\n",
      "RUN:  30\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 8s 207ms/step - loss: 0.1373 - val_loss: 0.1023\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1016 - val_loss: 0.0623\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0715 - val_loss: 0.0384\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0486 - val_loss: 0.0245\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0305 - val_loss: 0.0160\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0203 - val_loss: 0.0096\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0048\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0029\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0022\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0051 - val_loss: 0.0018\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prediction for:  2024-01-11         CLOSE:  2343.9932\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-177.16271972656213, 51.77315521384896)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTMPrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearningEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
